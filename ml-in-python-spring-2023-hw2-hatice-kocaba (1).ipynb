{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-05-13T07:35:03.528075Z","iopub.execute_input":"2023-05-13T07:35:03.528524Z","iopub.status.idle":"2023-05-13T07:35:03.543648Z","shell.execute_reply.started":"2023-05-13T07:35:03.528487Z","shell.execute_reply":"2023-05-13T07:35:03.542102Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/input/housing-prices-competition-for-kaggle-learn-users/train.csv\n/kaggle/input/housing-prices-competition-for-kaggle-learn-users/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Read the data\nX_full = pd.read_csv('../input/housing-prices-competition-for-kaggle-learn-users/train.csv', index_col='Id')\nX_test_full = pd.read_csv('../input/housing-prices-competition-for-kaggle-learn-users/test.csv', index_col='Id')\nprint(X_full.shape)\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\n# To keep things simple, we'll use only numerical predictors\nX = X_full.select_dtypes(exclude=['object'])\nX_test = X_test_full.select_dtypes(exclude=['object'])\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T07:35:03.546824Z","iopub.execute_input":"2023-05-13T07:35:03.547376Z","iopub.status.idle":"2023-05-13T07:35:03.621319Z","shell.execute_reply.started":"2023-05-13T07:35:03.547325Z","shell.execute_reply":"2023-05-13T07:35:03.620124Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(1460, 80)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T07:35:03.622902Z","iopub.execute_input":"2023-05-13T07:35:03.624117Z","iopub.status.idle":"2023-05-13T07:35:03.631558Z","shell.execute_reply.started":"2023-05-13T07:35:03.624066Z","shell.execute_reply":"2023-05-13T07:35:03.630352Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Question 1\ncols_with_missing = [col for col in X_train.columns\n                     if X_train[col].isnull().any()]\nreduced_X_train =  X_train.drop(cols_with_missing, axis=1)\nreduced_X_valid =  X_valid.drop(cols_with_missing, axis=1)\nprint(\"MAE (Drop columns with missing values):\")\nprint(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T07:35:03.634273Z","iopub.execute_input":"2023-05-13T07:35:03.635154Z","iopub.status.idle":"2023-05-13T07:35:05.011169Z","shell.execute_reply.started":"2023-05-13T07:35:03.635090Z","shell.execute_reply":"2023-05-13T07:35:05.009740Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"MAE (Drop columns with missing values):\n17837.82570776256\n","output_type":"stream"}]},{"cell_type":"code","source":"#Question 2\nfrom sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer(strategy='median')\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n\n\nimputed_X_train.columns = X_train.columns\nimputed_X_valid.columns = X_valid.columns\n\nprint(\"MAE (Imputation):\")\nprint(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T07:35:05.012539Z","iopub.execute_input":"2023-05-13T07:35:05.012991Z","iopub.status.idle":"2023-05-13T07:35:06.505017Z","shell.execute_reply.started":"2023-05-13T07:35:05.012946Z","shell.execute_reply":"2023-05-13T07:35:06.503359Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"MAE (Imputation):\n17791.59899543379\n","output_type":"stream"}]},{"cell_type":"code","source":"#Question 3\n\n# Make a copy of the original data frames\nX_train_plus = X_train.copy()\nX_valid_plus = X_valid.copy()\n\n# Create new feature columns indicating missing values\nfor col in X_train.columns:\n    if X_train[col].isnull().any():\n        X_train_plus[col + '_missing'] = X_train[col].isnull()\n        X_valid_plus[col + '_missing'] = X_valid[col].isnull()\n\n# Impute missing values using SimpleImputer\nimputer = SimpleImputer(strategy='median')\nimputed_X_train_plus = pd.DataFrame(imputer.fit_transform(X_train_plus))\nimputed_X_valid_plus = pd.DataFrame(imputer.transform(X_valid_plus))\n\n# Transfer column names from X_train_plus to imputed_X_train_plus and from X_valid_plus to imputed_X_valid_plus\nimputed_X_train_plus.columns = X_train_plus.columns\nimputed_X_valid_plus.columns = X_valid_plus.columns\n\n# Compute and print the MAE on the validation set\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)\n\nprint(\"MAE (Imputation_plus_median):\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T07:35:06.506779Z","iopub.execute_input":"2023-05-13T07:35:06.507173Z","iopub.status.idle":"2023-05-13T07:35:08.012926Z","shell.execute_reply.started":"2023-05-13T07:35:06.507140Z","shell.execute_reply":"2023-05-13T07:35:08.011876Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"MAE (Imputation_plus_median):\n18063.910194063923\n","output_type":"stream"}]},{"cell_type":"code","source":"#Question 4\n\n# Drop columns with missing values from X and X_test\nreduced_X = X.drop(cols_with_missing, axis=1)\nreduced_X_test = X_test.drop(cols_with_missing, axis=1)\n\n# Impute missing values using SimpleImputer on reduced_X and reduced_X_test\nimputer = SimpleImputer(strategy='median')\nreduced_imputed_X = pd.DataFrame(imputer.fit_transform(reduced_X))\nreduced_imputed_X_test = pd.DataFrame(imputer.transform(reduced_X_test))\n\n# Transfer column names from reduced_X to reduced_imputed_X and from reduced_X_test to reduced_imputed_X_test\nreduced_imputed_X.columns = reduced_X.columns\nreduced_imputed_X_test.columns = reduced_X_test.columns\n\n# Train a random forest model\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(reduced_imputed_X, y)\n\n# Generate predictions on the test set\npreds_test = model.predict(reduced_imputed_X_test)\n\n# Save predictions as a pandas data frame and convert it to a csv file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission_drop_columns.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T07:35:08.014521Z","iopub.execute_input":"2023-05-13T07:35:08.014873Z","iopub.status.idle":"2023-05-13T07:35:09.704027Z","shell.execute_reply.started":"2023-05-13T07:35:08.014839Z","shell.execute_reply":"2023-05-13T07:35:09.702741Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"score :16381.48041","metadata":{}},{"cell_type":"code","source":"#Question 5\n\n# Impute missing values in X and X_test using SimpleImputer\nimputer = SimpleImputer(strategy='median')\nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X_test = pd.DataFrame(imputer.transform(X_test))\n\n# Transfer column names from X to imputed_X and from X_test to imputed_X_test\nimputed_X.columns = X.columns\nimputed_X_test.columns = X_test.columns\n\n# Train a random forest model\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(imputed_X, y)\n\n# Generate predictions on the test set\npreds_test = model.predict(imputed_X_test)\n\n# Save predictions as a pandas data frame and convert it to a csv file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission_impute_median.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T07:35:09.705666Z","iopub.execute_input":"2023-05-13T07:35:09.706452Z","iopub.status.idle":"2023-05-13T07:35:11.557311Z","shell.execute_reply.started":"2023-05-13T07:35:09.706375Z","shell.execute_reply":"2023-05-13T07:35:11.556065Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Score: 16452.43726","metadata":{}},{"cell_type":"code","source":"#Question 6\nX_plus = X.copy()\nX_test_plus = X_test.copy()\n\n# Create new feature columns indicating missing values\nfor col in X.columns:\n    if X[col].isnull().any():\n        X_plus[col + '_missing'] = X[col].isnull()\n        X_test_plus[col + '_missing'] = X_test[col].isnull()\n\n# Apply SimpleImputer after adding new columns for columns with missing values\nimputer = SimpleImputer(strategy='median')\nimputed_X_plus = pd.DataFrame(imputer.fit_transform(X_plus))\nimputed_X_test_plus = pd.DataFrame(imputer.transform(X_test_plus))\n\n# Transfer column names from X_plus to imputed_X_plus and from X_test_plus to imputed_X_test_plus\nimputed_X_plus.columns = X_plus.columns\nimputed_X_test_plus.columns = X_test_plus.columns\n\n# Train a random forest model\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(imputed_X_plus, y)\n\n# Generate predictions on the test set\npredictions = model.predict(imputed_X_test_plus)\n\n# Save predictions as a pandas data frame and convert it to a csv file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission_impute_plus_median.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T07:35:11.558830Z","iopub.execute_input":"2023-05-13T07:35:11.559177Z","iopub.status.idle":"2023-05-13T07:35:13.465904Z","shell.execute_reply.started":"2023-05-13T07:35:11.559146Z","shell.execute_reply":"2023-05-13T07:35:13.464772Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Score: 16452.43726","metadata":{}}]}